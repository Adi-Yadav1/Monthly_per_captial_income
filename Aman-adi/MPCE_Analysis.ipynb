{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Per Capita Expenditure (MPCE) Prediction\n",
    "\n",
    "This notebook analyzes the Monthly Per Capita Expenditure (MPCE) dataset and builds predictive models to help the Government of India in budget planning and execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "We'll start by loading the dataset and examining its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsRegressor\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVR\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score, mean_absolute_error\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set the style for plots\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('mpce_dataset.csv')\n",
    "print(f\"Dataset loaded with {df.shape[0]} rows and {df.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Information and Details\n",
    "\n",
    "Let's examine the dataset structure, data types, and summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset information\n",
    "print(\"\\nDataset Information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Cleaning\n",
    "\n",
    "We'll handle missing values, duplicates, and validate the MPCE calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the dataframe to avoid modifying the original\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Handle missing values if any\n",
    "if df_cleaned.isnull().sum().sum() > 0:\n",
    "    # For numerical columns, fill with median\n",
    "    num_cols = df_cleaned.select_dtypes(include=['int64', 'float64']).columns\n",
    "    for col in num_cols:\n",
    "        if df_cleaned[col].isnull().sum() > 0:\n",
    "            df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)\n",
    "    \n",
    "    # For categorical columns, fill with mode\n",
    "    cat_cols = df_cleaned.select_dtypes(include=['object']).columns\n",
    "    for col in cat_cols:\n",
    "        if df_cleaned[col].isnull().sum() > 0:\n",
    "            df_cleaned[col].fillna(df_cleaned[col].mode()[0], inplace=True)\n",
    "\n",
    "# Remove duplicate rows if any\n",
    "if duplicates > 0:\n",
    "    df_cleaned = df_cleaned.drop_duplicates()\n",
    "    print(f\"Removed {duplicates} duplicate rows.\")\n",
    "\n",
    "# Check if MPCE is calculated correctly (Total_Expenditure / Household_Size)\n",
    "df_cleaned['Calculated_MPCE'] = df_cleaned['Total_Expenditure'] / df_cleaned['Household_Size']\n",
    "mpce_diff = (df_cleaned['MPCE'] - df_cleaned['Calculated_MPCE']).abs()\n",
    "print(f\"Max difference between provided MPCE and calculated MPCE: {mpce_diff.max()}\")\n",
    "print(f\"Mean difference between provided MPCE and calculated MPCE: {mpce_diff.mean()}\")\n",
    "\n",
    "# If the difference is negligible, we can use the provided MPCE\n",
    "# Otherwise, we might want to recalculate it\n",
    "if mpce_diff.mean() < 0.01:\n",
    "    print(\"MPCE values are correctly calculated.\")\n",
    "else:\n",
    "    print(\"There might be discrepancies in MPCE calculation.\")\n",
    "\n",
    "# Drop the calculated MPCE column as we'll use the original\n",
    "df_cleaned.drop('Calculated_MPCE', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's explore the relationships between different variables and MPCE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Distribution of MPCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for saving plots\n",
    "import os\n",
    "if not os.path.exists('plots'):\n",
    "    os.makedirs('plots')\n",
    "\n",
    "# EDA 1: Distribution of MPCE\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_cleaned['MPCE'], kde=True)\n",
    "plt.title('Distribution of Monthly Per Capita Expenditure (MPCE)')\n",
    "plt.xlabel('MPCE')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('plots/mpce_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 MPCE by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA 2: MPCE by State\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='State', y='MPCE', data=df_cleaned)\n",
    "plt.title('MPCE Distribution by State')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/mpce_by_state.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 MPCE by Rural/Urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA 3: MPCE by Rural/Urban\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Rural_Urban', y='MPCE', data=df_cleaned)\n",
    "plt.title('MPCE Distribution by Rural/Urban')\n",
    "plt.savefig('plots/mpce_by_rural_urban.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA 4: Correlation between MPCE and other numerical variables\n",
    "numerical_cols = df_cleaned.select_dtypes(include=['int64', 'float64']).columns\n",
    "correlation = df_cleaned[numerical_cols].corr()\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix of Numerical Variables')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/correlation_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 MPCE by Education Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA 5: MPCE by Education Level\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='Education_Level', y='MPCE', data=df_cleaned)\n",
    "plt.title('MPCE Distribution by Education Level')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/mpce_by_education.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 MPCE by Employment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA 6: MPCE by Employment Status\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='Employment_Status', y='MPCE', data=df_cleaned)\n",
    "plt.title('MPCE Distribution by Employment Status')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/mpce_by_employment.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 MPCE vs Monthly Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA 7: Scatter plot of MPCE vs Monthly Income\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Monthly_Income', y='MPCE', data=df_cleaned)\n",
    "plt.title('MPCE vs Monthly Income')\n",
    "plt.savefig('plots/mpce_vs_income.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering and Selection\n",
    "\n",
    "Let's prepare the data for modeling by selecting and transforming relevant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Household_ID column as it's just an identifier\n",
    "df_cleaned.drop('Household_ID', axis=1, inplace=True)\n",
    "\n",
    "# Define features and target variable\n",
    "X = df_cleaned.drop('MPCE', axis=1)\n",
    "y = df_cleaned['MPCE']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Print the columns\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "print(f\"Numerical columns: {numerical_cols}\")\n",
    "\n",
    "# Create preprocessing pipelines for both numerical and categorical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Selection and Training\n",
    "\n",
    "We'll train and evaluate multiple regression models to predict MPCE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models to evaluate\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'KNN Regressor': KNeighborsRegressor(),\n",
    "    'Support Vector Regressor': SVR(),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Dictionary to store model results\n",
    "model_results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Create a pipeline with preprocessing and the model\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Store the results\n",
    "    model_results[name] = {\n",
    "        'pipeline': pipeline,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} - MSE: {mse:.2f}, RMSE: {rmse:.2f}, MAE: {mae:.2f}, R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison and Selection\n",
    "\n",
    "Let's compare the models and select the best one based on R² score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models based on R² score\n",
    "r2_scores = {name: results['r2'] for name, results in model_results.items()}\n",
    "best_model_name = max(r2_scores, key=r2_scores.get)\n",
    "best_model = model_results[best_model_name]['pipeline']\n",
    "\n",
    "print(f\"\\nBest model based on R² score: {best_model_name} with R² = {r2_scores[best_model_name]:.4f}\")\n",
    "\n",
    "# Create a bar chart to compare R² scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "models_names = list(r2_scores.keys())\n",
    "r2_values = list(r2_scores.values())\n",
    "bars = plt.bar(models_names, r2_values, color='skyblue')\n",
    "plt.title('Model Comparison - R² Score')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('R² Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Highlight the best model\n",
    "best_index = models_names.index(best_model_name)\n",
    "bars[best_index].set_color('green')\n",
    "\n",
    "plt.savefig('plots/model_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save the Best Model\n",
    "\n",
    "Let's save the best model for later use in the Streamlit application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "with open('best_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "print(f\"Best model ({best_model_name}) saved as 'best_model.pkl'\")\n",
    "\n",
    "print(\"\\nAnalysis and model training completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance Analysis\n",
    "\n",
    "Let's analyze which features are most important for predicting MPCE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the best model is Random Forest or XGBoost, we can extract feature importances\n",
    "if best_model_name in ['Random Forest', 'XGBoost']:\n",
    "    # Get the feature names after preprocessing\n",
    "    # This is a bit complex due to the preprocessing pipeline\n",
    "    # We'll use a simpler approach by training a model directly on the data\n",
    "    \n",
    "    if best_model_name == 'Random Forest':\n",
    "        direct_model = RandomForestRegressor(random_state=42)\n",
    "    else:  # XGBoost\n",
    "        direct_model = XGBRegressor(random_state=42)\n",
    "    \n",
    "    # We need to preprocess the data first\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    \n",
    "    # Train the model\n",
    "    direct_model.fit(X_train_processed, y_train)\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = direct_model.feature_importances_\n",
    "    \n",
    "    # Get feature names (this is approximate as we don't have exact names after one-hot encoding)\n",
    "    feature_names = numerical_cols.copy()\n",
    "    for cat in categorical_cols:\n",
    "        unique_values = X_train[cat].unique()\n",
    "        for val in unique_values:\n",
    "            feature_names.append(f\"{cat}_{val}\")\n",
    "    \n",
    "    # Limit to the number of importances we have\n",
    "    feature_names = feature_names[:len(importances)]\n",
    "    \n",
    "    # Create a dataframe for visualization\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    })\n",
    "    \n",
    "    # Sort by importance\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False).head(20)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "    plt.title(f'Top 20 Feature Importances - {best_model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/feature_importance.png')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Feature importance analysis not available for {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "In this notebook, we've analyzed the MPCE dataset, built predictive models, and selected the best model for deployment. The Streamlit application will use this model to provide MPCE predictions and insights for government budget planning and execution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
